#R36. use subprocess to manage sub process
see the code

#R37. use threads for IO tensive task, not for parallelism task
due to GIL global interpreter lock
two ways to resolve IO tensive task: multi threads or async IO

#R38. use lock to avoid data competition 
GIL won't lock the data, any other process can break in when one process is running

#R39. use Queue to cordinate work between different threads
a. another loop to check if the done_queu has all items
b. cannot stop worker
c. incase any step gets delay, more data rushed in and caused the code to overflow

#R40. use coroutine 协程 to run multiple functions concurrently
threads' problems:
a. additional code to manage the threads
b. 8MB for each thread, too much memory
c. too much thread start overhead 

coroutine's cost is similiar to a function call, each coroutine takes 1KB memory

#R41. use concurrent.futures to implement the real parallel computing
multiprocess will trigger multiple process and each process will have a GIL
due to that, each process won't lock each other simply because there is no a global GIL
a. pass each pair of numbers to map
b. pickle module will serialize each number to binary
c. local socket will get the serialized data in primary process and pass to non primary process
d. in non primary process, pickle module will deserialize the binary data and reset it to a python object
e. import gcd
f. each non primary process will run gcd
g. execution result will be serialized and copy through socket to primary process
h. primary process will deserialize the data to python object
i. merge the object to a list

other programming language will require a lock to coordinate the multiple processes in the backend.
python requires more. python requires serialize and deserialize between each processes' communications.

we should try ThreadPoolExecutor first, then ProcessPoolExecutor and last multiprocessing advance futures 
such as shared memory, cross process lock, queue, proxy, etc.

